package main

import "github.com/c-bata/go-prompt"

var CommonArgs = []prompt.Suggest{
	{Text: "--acd-auth-url", Description: "Auth server URL."},
	{Text: "--acd-client-id", Description: "Amazon Application Client ID."},
	{Text: "--acd-client-secret", Description: "Amazon Application Client Secret."},
	{Text: "--acd-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--acd-templink-threshold", Description: "Files >= this size will be downloaded via their tempLink."},
	{Text: "--acd-token-url", Description: "Token server url."},
	{Text: "--acd-upload-wait-per-gb", Description: "Additional time per GB to wait after a failed complete upload to see if it appears."},
	{Text: "--alias-remote", Description: "Remote or path to alias."},
	{Text: "--ask-password", Description: "Allow prompt for password for encrypted configuration."},
	{Text: "--auto-confirm", Description: "If enabled, do not request console confirmation."},
	{Text: "--azureblob-access-tier", Description: "Access tier of blob: hot, cool or archive."},
	{Text: "--azureblob-account", Description: "Storage Account Name (leave blank to use SAS URL or Emulator)"},
	{Text: "--azureblob-chunk-size", Description: "Upload chunk size (<= 100MB)."},
	{Text: "--azureblob-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--azureblob-endpoint", Description: "Endpoint for the service"},
	{Text: "--azureblob-key", Description: "Storage Account Key (leave blank to use SAS URL or Emulator)"},
	{Text: "--azureblob-list-chunk", Description: "Size of blob list."},
	{Text: "--azureblob-sas-url", Description: "SAS URL for container level access only"},
	{Text: "--azureblob-upload-cutoff", Description: "Cutoff for switching to chunked upload (<= 256MB)."},
	{Text: "--azureblob-use-emulator", Description: "Uses local storage emulator if provided as '''true''' (leave blank if using real azure storage endpoint)"},
	{Text: "--b2-account", Description: "Account ID or Application Key ID"},
	{Text: "--b2-chunk-size", Description: "Upload chunk size. Must fit in memory."},
	{Text: "--b2-disable-checksum", Description: "Disable checksums for large (> upload cutoff) files"},
	{Text: "--b2-download-auth-duration", Description: "Time before the authorization token will expire in s or suffix ms|s|m|h|d."},
	{Text: "--b2-download-url", Description: "Custom endpoint for downloads."},
	{Text: "--b2-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--b2-endpoint", Description: "Endpoint for the service."},
	{Text: "--b2-hard-delete", Description: "Permanently delete files on remote removal, otherwise hide files."},
	{Text: "--b2-key", Description: "Application Key"},
	{Text: "--b2-test-mode", Description: "A flag string for X-Bz-Test-Mode header for debugging."},
	{Text: "--b2-upload-cutoff", Description: "Cutoff for switching to chunked upload."},
	{Text: "--b2-versions", Description: "Include old versions in directory listings."},
	{Text: "--backup-dir", Description: "Make backups into hierarchy based in DIR."},
	{Text: "--bind", Description: "Local address to bind to for outgoing connections, IPv4, IPv6 or name."},
	{Text: "--box-box-config-file", Description: "Box App config.json location"},
	{Text: "--box-box-sub-type", Description: ""},
	{Text: "--box-client-id", Description: "Box App Client Id."},
	{Text: "--box-client-secret", Description: "Box App Client Secret"},
	{Text: "--box-commit-retries", Description: "Max number of times to try committing a multipart file."},
	{Text: "--box-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--box-upload-cutoff", Description: "Cutoff for switching to multipart upload (>= 50MB)."},
	{Text: "--buffer-size", Description: "In memory buffer size when reading files for each --transfer."},
	{Text: "--bwlimit", Description: "Bandwidth limit in kBytes/s, or use suffix b|k|M|G or a full timetable."},
	{Text: "--ca-cert", Description: "CA certificate used to verify servers"},
	{Text: "--cache-chunk-clean-interval", Description: "How often should the cache perform cleanups of the chunk storage."},
	{Text: "--cache-chunk-no-memory", Description: "Disable the in-memory cache for storing chunks during streaming."},
	{Text: "--cache-chunk-path", Description: "Directory to cache chunk files."},
	{Text: "--cache-chunk-size", Description: "The size of a chunk (partial file data)."},
	{Text: "--cache-chunk-total-size", Description: "The total size that the chunks can take up on the local disk."},
	{Text: "--cache-db-path", Description: "Directory to store file structure metadata DB."},
	{Text: "--cache-db-purge", Description: "Clear all the cached data for this remote on start."},
	{Text: "--cache-db-wait-time", Description: "How long to wait for the DB to be available - 0 is unlimited"},
	{Text: "--cache-dir", Description: "Directory rclone will use for caching."},
	{Text: "--cache-info-age", Description: "How long to cache file structure information (directory listings, file size, times etc)."},
	{Text: "--cache-plex-insecure", Description: "Skip all certificate verifications when connecting to the Plex server"},
	{Text: "--cache-plex-password", Description: "The password of the Plex user"},
	{Text: "--cache-plex-url", Description: "The URL of the Plex server"},
	{Text: "--cache-plex-username", Description: "The username of the Plex user"},
	{Text: "--cache-read-retries", Description: "How many times to retry a read from a cache storage."},
	{Text: "--cache-remote", Description: "Remote to cache."},
	{Text: "--cache-rps", Description: "Limits the number of requests per second to the source FS (-1 to disable)"},
	{Text: "--cache-tmp-upload-path", Description: "Directory to keep temporary files until they are uploaded."},
	{Text: "--cache-tmp-wait-time", Description: "How long should files be stored in local cache before being uploaded"},
	{Text: "--cache-workers", Description: "How many workers should run in parallel to download chunks."},
	{Text: "--cache-writes", Description: "Cache file data on writes through the FS"},
	{Text: "--checkers", Description: "Number of checkers to run in parallel."},
	{Text: "(-c --checksum)'{-c,--checksum}'", Description: "Skip based on checksum (if available) & size, not mod-time & size"},
	{Text: "--chunker-chunk-size", Description: "Files larger than chunk size will be split in chunks."},
	{Text: "--chunker-fail-hard", Description: "Choose how chunker should handle files with missing or invalid chunks."},
	{Text: "--chunker-hash-type", Description: "Choose how chunker handles hash sums. All modes but 'none' require metadata."},
	{Text: "--chunker-meta-format", Description: "Format of the metadata object or 'none'. By default 'simplejson'."},
	{Text: "--chunker-name-format", Description: "String format of chunk file names."},
	{Text: "--chunker-remote", Description: "Remote to chunk/unchunk."},
	{Text: "--chunker-start-from", Description: "Minimum valid chunk number. Usually 0 or 1."},
	{Text: "--client-cert", Description: "Client SSL certificate (PEM) for mutual TLS auth"},
	{Text: "--client-key", Description: "Client SSL private key (PEM) for mutual TLS auth"},
	{Text: "--compare-dest", Description: "Include additional server-side path during comparison."},
	{Text: "--config", Description: "Config file."},
	{Text: "--contimeout", Description: "Connect timeout"},
	{Text: "--copy-dest", Description: "Implies --compare-dest but also copies files from path into destination."},
	{Text: "(-L --copy-links)'{-L,--copy-links}'", Description: "Follow symlinks and copy the pointed to item."},
	{Text: "--cpuprofile", Description: "Write cpu profile to file"},
	{Text: "--crypt-directory-name-encryption", Description: "Option to either encrypt directory names or leave them intact."},
	{Text: "--crypt-filename-encryption", Description: "How to encrypt the filenames."},
	{Text: "--crypt-password", Description: "Password or pass phrase for encryption."},
	{Text: "--crypt-password2", Description: "Password or pass phrase for salt. Optional but recommended."},
	{Text: "--crypt-remote", Description: "Remote to encrypt/decrypt."},
	{Text: "--crypt-show-mapping", Description: "For all files listed show how the names encrypt."},
	{Text: "--cutoff-mode", Description: "Mode to stop transfers when reaching the max transfer limit HARD|SOFT|CAUTIOUS"},
	{Text: "--delete-after", Description: "When synchronizing, delete files on destination after transferring (default)"},
	{Text: "--delete-before", Description: "When synchronizing, delete files on destination before transferring"},
	{Text: "--delete-during", Description: "When synchronizing, delete files during transfer"},
	{Text: "--delete-excluded", Description: "Delete files on dest excluded from sync"},
	{Text: "--disable", Description: "Disable a comma separated list of features.  Use help to see a list."},
	{Text: "--drive-acknowledge-abuse", Description: "Set to allow files which return cannotDownloadAbusiveFile to be downloaded."},
	{Text: "--drive-allow-import-name-change", Description: "Allow the filetype to change when uploading Google docs (e.g. file.doc to file.docx). This will confuse sync and reupload every time."},
	{Text: "--drive-alternate-export", Description: "Use alternate export URLs for google documents export.,"},
	{Text: "--drive-auth-owner-only", Description: "Only consider files owned by the authenticated user."},
	{Text: "--drive-chunk-size", Description: "Upload chunk size. Must a power of 2 >= 256k."},
	{Text: "--drive-client-id", Description: "Google Application Client Id"},
	{Text: "--drive-client-secret", Description: "Google Application Client Secret"},
	{Text: "--drive-disable-http2", Description: "Disable drive using http2"},
	{Text: "--drive-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--drive-export-formats", Description: "Comma separated list of preferred formats for downloading Google docs."},
	{Text: "--drive-formats", Description: "Deprecated: see export_formats"},
	{Text: "--drive-impersonate", Description: "Impersonate this user when using a service account."},
	{Text: "--drive-import-formats", Description: "Comma separated list of preferred formats for uploading Google docs."},
	{Text: "--drive-keep-revision-forever", Description: "Keep new head revision of each file forever."},
	{Text: "--drive-list-chunk", Description: "Size of listing chunk 100-1000. 0 to disable."},
	{Text: "--drive-pacer-burst", Description: "Number of API calls to allow without sleeping."},
	{Text: "--drive-pacer-min-sleep", Description: "Minimum time to sleep between API calls."},
	{Text: "--drive-root-folder-id", Description: "ID of the root folder"},
	{Text: "--drive-scope", Description: "Scope that rclone should use when requesting access from drive."},
	{Text: "--drive-server-side-across-configs", Description: "Allow server side operations (eg copy) to work across different drive configs."},
	{Text: "--drive-service-account-credentials", Description: "Service Account Credentials JSON blob"},
	{Text: "--drive-service-account-file", Description: "Service Account Credentials JSON file path"},
	{Text: "--drive-shared-with-me", Description: "Only show files that are shared with me."},
	{Text: "--drive-size-as-quota", Description: "Show sizes as storage quota usage, not actual size."},
	{Text: "--drive-skip-checksum-gphotos", Description: "Skip MD5 checksum on Google photos and videos only."},
	{Text: "--drive-skip-gdocs", Description: "Skip google documents in all listings."},
	{Text: "--drive-stop-on-upload-limit", Description: "Make upload limit errors be fatal"},
	{Text: "--drive-team-drive", Description: "ID of the Team Drive"},
	{Text: "--drive-trashed-only", Description: "Only show files that are in the trash."},
	{Text: "--drive-upload-cutoff", Description: "Cutoff for switching to chunked upload"},
	{Text: "--drive-use-created-date", Description: "Use file created date instead of modified date.,"},
	{Text: "--drive-use-shared-date", Description: "Use date file was shared instead of modified date."},
	{Text: "--drive-use-trash", Description: "Send files to the trash instead of deleting permanently."},
	{Text: "--drive-v2-download-min-size", Description: "If Object'''s are greater, use drive v2 API to download."},
	{Text: "--dropbox-chunk-size", Description: "Upload chunk size. (< 150M)."},
	{Text: "--dropbox-client-id", Description: "Dropbox App Client Id"},
	{Text: "--dropbox-client-secret", Description: "Dropbox App Client Secret"},
	{Text: "--dropbox-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--dropbox-impersonate", Description: "Impersonate this user when using a business account."},
	{Text: "(-n --dry-run)'{-n,--dry-run}'", Description: "Do a trial run with no permanent changes"},
	{Text: "--dump", Description: "List of items to dump from: headers,bodies,requests,responses,auth,filters,goroutines,openfiles"},
	{Text: "--dump-bodies", Description: "Dump HTTP headers and bodies - may contain sensitive info"},
	{Text: "--dump-headers", Description: "Dump HTTP headers - may contain sensitive info"},
	{Text: "--error-on-no-transfer", Description: "Sets exit code 9 if no files are transferred, useful in scripts"},
	{Text: "*--exclude", Description: "Exclude files matching pattern"},
	{Text: "*--exclude-from", Description: "Read exclude patterns from file (use - to read from stdin)"},
	{Text: "--exclude-if-present", Description: "Exclude directories if filename is present"},
	{Text: "--expect-continue-timeout", Description: "Timeout when using expect / 100-continue in HTTP"},
	{Text: "--fast-list", Description: "Use recursive list if available. Uses more memory but fewer transactions."},
	{Text: "--fichier-api-key", Description: "Your API Key, get it from https://1fichier.com/console/params.pl"},
	{Text: "--fichier-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--fichier-shared-folder", Description: "If you want to download a shared folder, add this parameter"},
	{Text: "*--files-from", Description: "Read list of source-file names from file (use - to read from stdin)"},
	{Text: "*--files-from-raw", Description: "Read list of source-file names from file without any processing of lines (use - to read from stdin)"},
	{Text: "(*-f *--filter)'{*-f,*--filter}'", Description: "Add a file-filtering rule"},
	{Text: "*--filter-from", Description: "Read filtering patterns from a file (use - to read from stdin)"},
	{Text: "--ftp-concurrency", Description: "Maximum number of FTP simultaneous connections, 0 for unlimited"},
	{Text: "--ftp-disable-epsv", Description: "Disable using EPSV even if server advertises support"},
	{Text: "--ftp-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--ftp-host", Description: "FTP host to connect to"},
	{Text: "--ftp-no-check-certificate", Description: "Do not verify the TLS certificate of the server"},
	{Text: "--ftp-pass", Description: "FTP password"},
	{Text: "--ftp-port", Description: "FTP port, leave blank to use default (21)"},
	{Text: "--ftp-tls", Description: "Use FTP over TLS (Implicit)"},
	{Text: "--ftp-user", Description: "FTP username, leave blank for current username, negative0"},
	{Text: "--gcs-bucket-acl", Description: "Access Control List for new buckets."},
	{Text: "--gcs-bucket-policy-only", Description: "Access checks should use bucket-level IAM policies."},
	{Text: "--gcs-client-id", Description: "Google Application Client Id"},
	{Text: "--gcs-client-secret", Description: "Google Application Client Secret"},
	{Text: "--gcs-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--gcs-location", Description: "Location for the newly created buckets."},
	{Text: "--gcs-object-acl", Description: "Access Control List for new objects."},
	{Text: "--gcs-project-number", Description: "Project number."},
	{Text: "--gcs-service-account-file", Description: "Service Account Credentials JSON file path"},
	{Text: "--gcs-storage-class", Description: "The storage class to use when storing objects in Google Cloud Storage."},
	{Text: "--gphotos-client-id", Description: "Google Application Client Id"},
	{Text: "--gphotos-client-secret", Description: "Google Application Client Secret"},
	{Text: "--gphotos-read-only", Description: "Set to make the Google Photos backend read only."},
	{Text: "--gphotos-read-size", Description: "Set to read the size of media items."},
	{Text: "--gphotos-start-year", Description: "Year limits the photos to be downloaded to those which are uploaded after the given year"},
	{Text: "--http-headers", Description: "Set HTTP headers for all transactions"},
	{Text: "--http-no-head", Description: "Don'''t use HEAD requests to find file sizes in dir listing"},
	{Text: "--http-no-slash", Description: "Set this if the site doesn'''t end directories with /"},
	{Text: "--http-url", Description: "URL of http host to connect to"},
	{Text: "--hubic-chunk-size", Description: "Above this size files will be chunked into a _segments container."},
	{Text: "--hubic-client-id", Description: "Hubic Client Id"},
	{Text: "--hubic-client-secret", Description: "Hubic Client Secret"},
	{Text: "--hubic-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--hubic-no-chunk", Description: "Don'''t chunk files during streaming upload."},
	{Text: "--ignore-case", Description: "Ignore case in filters (case insensitive)"},
	{Text: "--ignore-case-sync", Description: "Ignore case when synchronizing"},
	{Text: "--ignore-checksum", Description: "Skip post copy check of checksums."},
	{Text: "--ignore-errors", Description: "delete even if there are I/O errors"},
	{Text: "--ignore-existing", Description: "Skip all files that exist on destination"},
	{Text: "--ignore-size", Description: "Ignore size when skipping use mod-time or checksum."},
	{Text: "(-I --ignore-times)'{-I,--ignore-times}'", Description: "Don'''t skip files that match size and time - transfer all files"},
	{Text: "--immutable", Description: "Do not modify files. Fail if existing files have been modified."},
	{Text: "*--include", Description: "Include files matching pattern"},
	{Text: "*--include-from", Description: "Read include patterns from file (use - to read from stdin)"},
	{Text: "--jottacloud-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--jottacloud-hard-delete", Description: "Delete files permanently rather than putting them into the trash."},
	{Text: "--jottacloud-md5-memory-limit", Description: "Files bigger than this will be cached on disk to calculate the MD5 if required."},
	{Text: "--jottacloud-trashed-only", Description: "Only show files that are in the trash."},
	{Text: "--jottacloud-unlink", Description: "Remove existing public link to file/folder with link command rather than creating."},
	{Text: "--jottacloud-upload-resume-limit", Description: "Files bigger than this can be resumed if the upload fail'''s."},
	{Text: "--koofr-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--koofr-endpoint", Description: "The Koofr API endpoint to use"},
	{Text: "--koofr-mountid", Description: "Mount ID of the mount to use. If omitted, the primary mount is used."},
	{Text: "--koofr-password", Description: "Your Koofr password for rclone (generate one at https://app.koofr.net/app/admin/preferences/password)"},
	{Text: "--koofr-setmtime", Description: "Does the backend support setting modification time. Set this to false if you use a mount ID that points to a Dropbox or Amazon Drive backend."},
	{Text: "--koofr-user", Description: "Your Koofr user name"},
	{Text: "(-l --links)'{-l,--links}'", Description: "Translate symlinks to/from regular files with a '''.rclonelink''' extension"},
	{Text: "--local-case-insensitive", Description: "Force the filesystem to report itself as case insensitive"},
	{Text: "--local-case-sensitive", Description: "Force the filesystem to report itself as case sensitive."},
	{Text: "--local-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--local-no-check-updated", Description: "Don'''t check to see if the files change during upload"},
	{Text: "--local-no-unicode-normalization", Description: "Don'''t apply unicode normalization to paths and filenames (Deprecated)"},
	{Text: "--local-nounc", Description: "Disable UNC (long path names) conversion on Windows"},
	{Text: "--log-file", Description: "Log everything to this file"},
	{Text: "--log-format", Description: "Comma separated list of log format options"},
	{Text: "--log-level", Description: "Log level DEBUG|INFO|NOTICE|ERROR"},
	{Text: "--low-level-retries", Description: "Number of low level retries to do."},
	{Text: "--mailru-check-hash", Description: "What should copy do if file checksum is mismatched or invalid"},
	{Text: "--mailru-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--mailru-pass", Description: "Password"},
	{Text: "--mailru-speedup-enable", Description: "Skip full upload if there is another file with same data hash."},
	{Text: "--mailru-speedup-file-patterns", Description: "Comma separated list of file name patterns eligible for speedup (put by hash)."},
	{Text: "--mailru-speedup-max-disk", Description: "This option allows you to disable speedup (put by hash) for large files"},
	{Text: "--mailru-speedup-max-memory", Description: "Files larger than the size given below will always be hashed on disk."},
	{Text: "--mailru-user", Description: "User name (usually email)"},
	{Text: "--max-age", Description: "Only transfer files younger than this in s or suffix ms|s|m|h|d|w|M|y"},
	{Text: "--max-backlog", Description: "Maximum number of objects in sync or check backlog."},
	{Text: "--max-delete", Description: "When synchronizing, limit the number of deletes"},
	{Text: "--max-depth", Description: "If set limits the recursion depth to this."},
	{Text: "--max-duration", Description: "Maximum duration rclone will transfer data for."},
	{Text: "--max-size", Description: "Only transfer files smaller than this in k or suffix b|k|M|G"},
	{Text: "--max-stats-groups", Description: "Maximum number of stats groups to keep in memory. On max oldest is discarded."},
	{Text: "--max-transfer", Description: "Maximum size of data to transfer."},
	{Text: "--mega-debug", Description: "Output more debug from Mega."},
	{Text: "--mega-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--mega-hard-delete", Description: "Delete files permanently rather than putting them into the trash."},
	{Text: "--mega-pass", Description: "Password."},
	{Text: "--mega-user", Description: "User name"},
	{Text: "--memprofile", Description: "Write memory profile to file"},
	{Text: "--min-age", Description: "Only transfer files older than this in s or suffix ms|s|m|h|d|w|M|y"},
	{Text: "--min-size", Description: "Only transfer files bigger than this in k or suffix b|k|M|G"},
	{Text: "--modify-window", Description: "Max time diff to be considered the same"},
	{Text: "--multi-thread-cutoff", Description: "Use multi-thread downloads for files above this size."},
	{Text: "--multi-thread-streams", Description: "Max number of streams to use for multi-thread downloads."},
	{Text: "--no-check-certificate", Description: "Do not verify the server SSL certificate. Insecure."},
	{Text: "--no-check-dest", Description: "Don'''t check the destination, copy regardless."},
	{Text: "--no-gzip-encoding", Description: "Don'''t set Accept-Encoding: gzip."},
	{Text: "--no-traverse", Description: "Don'''t traverse destination file system on copy."},
	{Text: "--no-update-modtime", Description: "Don'''t update destination mod-time if files identical."},
	{Text: "(-x --one-file-system)'{-x,--one-file-system}'", Description: "Don'''t cross filesystem boundaries (unix/macOS only)."},
	{Text: "--onedrive-chunk-size", Description: "Chunk size to upload files with - must be multiple of 320k (327,680 bytes)."},
	{Text: "--onedrive-client-id", Description: "Microsoft App Client Id"},
	{Text: "--onedrive-client-secret", Description: "Microsoft App Client Secret"},
	{Text: "--onedrive-drive-id", Description: "The ID of the drive to use"},
	{Text: "--onedrive-drive-type", Description: "The type of the drive ( personal | business | documentLibrary )"},
	{Text: "--onedrive-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--onedrive-expose-onenote-files", Description: "Set to make OneNote files show up in directory listings."},
	{Text: "--onedrive-server-side-across-configs", Description: "Allow server side operations (eg copy) to work across different onedrive configs."},
	{Text: "--opendrive-chunk-size", Description: "Files will be uploaded in chunks this size."},
	{Text: "--opendrive-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--opendrive-password", Description: "Password."},
	{Text: "--opendrive-username", Description: "Username"},
	{Text: "--order-by", Description: "Instructions on how to order the transfers, eg '''size,descending'''"},
	{Text: "--password-command", Description: "Command for supplying password for encrypted configuration."},
	{Text: "--pcloud-client-id", Description: "Pcloud App Client Id"},
	{Text: "--pcloud-client-secret", Description: "Pcloud App Client Secret"},
	{Text: "--pcloud-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--premiumizeme-encoding", Description: "This sets the encoding for the backend."},
	{Text: "(-P --progress)'{-P,--progress}'", Description: "Show progress during transfer."},
	{Text: "--putio-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--qingstor-access-key-id", Description: "QingStor Access Key ID"},
	{Text: "--qingstor-chunk-size", Description: "Chunk size to use for uploading."},
	{Text: "--qingstor-connection-retries", Description: "Number of connection retries."},
	{Text: "--qingstor-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--qingstor-endpoint", Description: "Enter a endpoint URL to connection QingStor API."},
	{Text: "--qingstor-env-auth", Description: "Get QingStor credentials from runtime. Only applies if access_key_id and secret_access_key is blank."},
	{Text: "--qingstor-secret-access-key", Description: "QingStor Secret Access Key (password)"},
	{Text: "--qingstor-upload-concurrency", Description: "Concurrency for multipart uploads."},
	{Text: "--qingstor-upload-cutoff", Description: "Cutoff for switching to chunked upload"},
	{Text: "--qingstor-zone", Description: "Zone to connect to."},
	{Text: "(-q --quiet)'{-q,--quiet}'", Description: "Print as little stuff as possible"},
	{Text: "--rc", Description: "Enable the remote control server."},
	{Text: "--rc-addr", Description: "IPaddress:Port or :Port to bind server to."},
	{Text: "--rc-allow-origin", Description: "Set the allowed origin for CORS."},
	{Text: "--rc-baseurl", Description: "Prefix for URLs - leave blank for root."},
	{Text: "--rc-cert", Description: "SSL PEM key (concatenation of certificate and CA certificate)"},
	{Text: "--rc-client-ca", Description: "Client certificate authority to verify clients with"},
	{Text: "--rc-enable-metrics", Description: "Enable prometheus metrics on /metrics"},
	{Text: "--rc-files", Description: "Path to local files to serve on the HTTP server."},
	{Text: "--rc-htpasswd", Description: "htpasswd file - if not provided no authentication is done"},
	{Text: "--rc-job-expire-duration", Description: "expire finished async jobs older than this value"},
	{Text: "--rc-job-expire-interval", Description: "interval to check for expired async jobs"},
	{Text: "--rc-key", Description: "SSL PEM Private key"},
	{Text: "--rc-max-header-bytes", Description: "Maximum size of request header"},
	{Text: "--rc-no-auth", Description: "Don'''t require auth for certain methods."},
	{Text: "--rc-pass", Description: "Password for authentication."},
	{Text: "--rc-realm", Description: "realm for authentication"},
	{Text: "--rc-serve", Description: "Enable the serving of remote objects."},
	{Text: "--rc-server-read-timeout", Description: "Timeout for server reading data"},
	{Text: "--rc-server-write-timeout", Description: "Timeout for server writing data"},
	{Text: "--rc-user", Description: "User name for authentication."},
	{Text: "--rc-web-fetch-url", Description: "URL to fetch the releases for webgui."},
	{Text: "--rc-web-gui", Description: "Launch WebGUI on localhost"},
	{Text: "--rc-web-gui-force-update", Description: "Force update to latest version of web gui"},
	{Text: "--rc-web-gui-no-open-browser", Description: "Don'''t open the browser automatically"},
	{Text: "--rc-web-gui-update", Description: "Check and update to latest version of web gui"},
	{Text: "--retries", Description: "Retry operations this many times if they fail"},
	{Text: "--retries-sleep", Description: "Interval between retrying operations if they fail, e.g 500ms, 60s, 5m. (0 to disable)"},
	{Text: "--s3-access-key-id", Description: "AWS Access Key ID."},
	{Text: "--s3-acl", Description: "Canned ACL used when creating buckets and storing or copying objects."},
	{Text: "--s3-bucket-acl", Description: "Canned ACL used when creating buckets."},
	{Text: "--s3-chunk-size", Description: "Chunk size to use for uploading."},
	{Text: "--s3-copy-cutoff", Description: "Cutoff for switching to multipart copy"},
	{Text: "--s3-disable-checksum", Description: "Don'''t store MD5 checksum with object metadata"},
	{Text: "--s3-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--s3-endpoint", Description: "Endpoint for S3 API."},
	{Text: "--s3-env-auth", Description: "Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars)."},
	{Text: "--s3-force-path-style", Description: "If true use path style access if false use virtual hosted style."},
	{Text: "--s3-leave-parts-on-error", Description: "If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery."},
	{Text: "--s3-list-chunk", Description: "Size of listing chunk (response list for each ListObject S3 request)."},
	{Text: "--s3-location-constraint", Description: "Location constraint - must be set to match the Region."},
	{Text: "--s3-memory-pool-flush-time", Description: "How often internal memory buffer pools will be flushed."},
	{Text: "--s3-memory-pool-use-mmap", Description: "Whether to use mmap buffers in internal memory pool."},
	{Text: "--s3-provider", Description: "Choose your S3 provider."},
	{Text: "--s3-region", Description: "Region to connect to."},
	{Text: "--s3-secret-access-key", Description: "AWS Secret Access Key (password)"},
	{Text: "--s3-server-side-encryption", Description: "The server-side encryption algorithm used when storing this object in S3."},
	{Text: "--s3-session-token", Description: "An AWS session token"},
	{Text: "--s3-sse-customer-algorithm", Description: "If using SSE-C, the server-side encryption algorithm used when storing this object in S3."},
	{Text: "--s3-sse-customer-key", Description: "If using SSE-C you must provide the secret encyption key used to encrypt/decrypt your data."},
	{Text: "--s3-sse-customer-key-md5", Description: "If using SSE-C you must provide the secret encryption key MD5 checksum."},
	{Text: "--s3-sse-kms-key-id", Description: "If using KMS ID you must provide the ARN of Key."},
	{Text: "--s3-storage-class", Description: "The storage class to use when storing new objects in S3."},
	{Text: "--s3-upload-concurrency", Description: "Concurrency for multipart uploads."},
	{Text: "--s3-upload-cutoff", Description: "Cutoff for switching to chunked upload"},
	{Text: "--s3-use-accelerate-endpoint", Description: "If true use the AWS S3 accelerated endpoint."},
	{Text: "--s3-v2-auth", Description: "If true use v2 authentication."},
	{Text: "--sftp-ask-password", Description: "Allow asking for SFTP password when needed."},
	{Text: "--sftp-disable-hashcheck", Description: "Disable the execution of SSH commands to determine if remote file hashing is available."},
	{Text: "--sftp-host", Description: "SSH host to connect to"},
	{Text: "--sftp-key-file", Description: "Path to PEM-encoded private key file, leave blank or set key-use-agent to use ssh-agent."},
	{Text: "--sftp-key-file-pass", Description: "The passphrase to decrypt the PEM-encoded private key file."},
	{Text: "--sftp-key-use-agent", Description: "When set forces the usage of the ssh-agent."},
	{Text: "--sftp-md5sum-command", Description: "The command used to read md5 hashes. Leave blank for autodetect."},
	{Text: "--sftp-pass", Description: "SSH password, leave blank to use ssh-agent."},
	{Text: "--sftp-path-override", Description: "Override path used by SSH connection."},
	{Text: "--sftp-port", Description: "SSH port, leave blank to use default (22)"},
	{Text: "--sftp-set-modtime", Description: "Set the modified time on the remote if set."},
	{Text: "--sftp-sha1sum-command", Description: "The command used to read sha1 hashes. Leave blank for autodetect."},
	{Text: "--sftp-skip-links", Description: "Set to skip any symlinks and any other non regular files."},
	{Text: "--sftp-use-insecure-cipher", Description: "Enable the use of insecure ciphers and key exchange methods."},
	{Text: "--sftp-user", Description: "SSH username, leave blank for current username, negative0"},
	{Text: "--sharefile-chunk-size", Description: "Upload chunk size. Must a power of 2 >= 256k."},
	{Text: "--sharefile-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--sharefile-endpoint", Description: "Endpoint for API calls."},
	{Text: "--sharefile-root-folder-id", Description: "ID of the root folder"},
	{Text: "--sharefile-upload-cutoff", Description: "Cutoff for switching to multipart upload."},
	{Text: "--size-only", Description: "Skip based on size only, not mod-time or checksum"},
	{Text: "--skip-links", Description: "Don'''t warn about skipped symlinks."},
	{Text: "--stats", Description: "Interval between printing stats, e.g 500ms, 60s, 5m. (0 to disable)"},
	{Text: "--stats-file-name-length", Description: "Max file name length in stats. 0 for no limit"},
	{Text: "--stats-log-level", Description: "Log level to show --stats output DEBUG|INFO|NOTICE|ERROR"},
	{Text: "--stats-one-line", Description: "Make the stats fit on one line."},
	{Text: "--stats-one-line-date", Description: "Enables --stats-one-line and add current date/time prefix."},
	{Text: "--stats-one-line-date-format", Description: "Enables --stats-one-line-date and uses custom formatted date. Enclose date string in double quotes ('). See https://golang.org/pkg/time/#Time.Format"},
	{Text: "--stats-unit", Description: "Show data rate in stats as either '''bits''' or '''bytes'''/s"},
	{Text: "--streaming-upload-cutoff", Description: "Cutoff for switching to chunked upload if file size is unknown. Upload starts after reaching cutoff or when file ends."},
	{Text: "--suffix", Description: "Suffix to add to changed files."},
	{Text: "--suffix-keep-extension", Description: "Preserve the extension when using --suffix."},
	{Text: "--sugarsync-access-key-id", Description: "Sugarsync Access Key ID."},
	{Text: "--sugarsync-app-id", Description: "Sugarsync App ID."},
	{Text: "--sugarsync-authorization", Description: "Sugarsync authorization"},
	{Text: "--sugarsync-authorization-expiry", Description: "Sugarsync authorization expiry"},
	{Text: "--sugarsync-deleted-id", Description: "Sugarsync deleted folder id"},
	{Text: "--sugarsync-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--sugarsync-hard-delete", Description: "Permanently delete files if true"},
	{Text: "--sugarsync-private-access-key", Description: "Sugarsync Private Access Key"},
	{Text: "--sugarsync-refresh-token", Description: "Sugarsync refresh token"},
	{Text: "--sugarsync-root-id", Description: "Sugarsync root id"},
	{Text: "--sugarsync-user", Description: "Sugarsync user"},
	{Text: "--swift-application-credential-id", Description: "Application Credential ID (OS_APPLICATION_CREDENTIAL_ID)"},
	{Text: "--swift-application-credential-name", Description: "Application Credential Name (OS_APPLICATION_CREDENTIAL_NAME)"},
	{Text: "--swift-application-credential-secret", Description: "Application Credential Secret (OS_APPLICATION_CREDENTIAL_SECRET)"},
	{Text: "--swift-auth", Description: "Authentication URL for server (OS_AUTH_URL)."},
	{Text: "--swift-auth-token", Description: "Auth Token from alternate authentication - optional (OS_AUTH_TOKEN)"},
	{Text: "--swift-auth-version", Description: "AuthVersion - optional - set to (1,2,3) if your auth URL has no version (ST_AUTH_VERSION)"},
	{Text: "--swift-chunk-size", Description: "Above this size files will be chunked into a _segments container."},
	{Text: "--swift-domain", Description: "User domain - optional (v3 auth) (OS_USER_DOMAIN_NAME)"},
	{Text: "--swift-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--swift-endpoint-type", Description: "Endpoint type to choose from the service catalogue (OS_ENDPOINT_TYPE)"},
	{Text: "--swift-env-auth", Description: "Get swift credentials from environment variables in standard OpenStack form."},
	{Text: "--swift-key", Description: "API key or password (OS_PASSWORD)."},
	{Text: "--swift-no-chunk", Description: "Don'''t chunk files during streaming upload."},
	{Text: "--swift-region", Description: "Region name - optional (OS_REGION_NAME)"},
	{Text: "--swift-storage-policy", Description: "The storage policy to use when creating a new container"},
	{Text: "--swift-storage-url", Description: "Storage URL - optional (OS_STORAGE_URL)"},
	{Text: "--swift-tenant", Description: "Tenant name - optional for v1 auth, this or tenant_id required otherwise (OS_TENANT_NAME or OS_PROJECT_NAME)"},
	{Text: "--swift-tenant-domain", Description: "Tenant domain - optional (v3 auth) (OS_PROJECT_DOMAIN_NAME)"},
	{Text: "--swift-tenant-id", Description: "Tenant ID - optional for v1 auth, this or tenant required otherwise (OS_TENANT_ID)"},
	{Text: "--swift-user", Description: "User name to log in (OS_USERNAME)."},
	{Text: "--swift-user-id", Description: "User ID to log in - optional - most swift systems use user and leave this blank (v3 auth) (OS_USER_ID)."},
	{Text: "--syslog", Description: "Use Syslog for logging"},
	{Text: "--syslog-facility", Description: "Facility for syslog, eg KERN,USER,..."},
	{Text: "--timeout", Description: "IO idle timeout"},
	{Text: "--tpslimit", Description: "Limit HTTP transactions per second to this."},
	{Text: "--tpslimit-burst", Description: "Max burst of transactions for --tpslimit."},
	{Text: "--track-renames", Description: "When synchronizing, track file renames and do a server side move if possible"},
	{Text: "--track-renames-strategy", Description: "Strategies to use when synchronizing using track-renames hash|modtime"},
	{Text: "--transfers", Description: "Number of file transfers to run in parallel."},
	{Text: "--union-action-policy", Description: "Policy to choose upstream on ACTION category."},
	{Text: "--union-cache-time", Description: "Cache time of usage and free space (in seconds). This option is only useful when a path preserving policy is used."},
	{Text: "--union-create-policy", Description: "Policy to choose upstream on CREATE category."},
	{Text: "--union-search-policy", Description: "Policy to choose upstream on SEARCH category."},
	{Text: "--union-upstreams", Description: "List of space separated upstreams."},
	{Text: "(-u --update)'{-u,--update}'", Description: "Skip files that are newer on the destination."},
	{Text: "--use-cookies", Description: "Enable session cookiejar."},
	{Text: "--use-json-log", Description: "Use json log format."},
	{Text: "--use-mmap", Description: "Use mmap allocator (see docs)."},
	{Text: "--use-server-modtime", Description: "Use server modified time instead of object metadata"},
	{Text: "--user-agent", Description: "Set the user-agent to a specified string. The default is rclone/ version"},
	{Text: "(-v --verbose)'{-v,--verbose}'", Description: "Print lots more stuff (repeat for more)"},
	{Text: "(-V --version)'{-V,--version}'", Description: "Print the version number"},
	{Text: "--webdav-bearer-token", Description: "Bearer token instead of user/pass (eg a Macaroon)"},
	{Text: "--webdav-bearer-token-command", Description: "Command to run to get a bearer token"},
	{Text: "--webdav-pass", Description: "Password."},
	{Text: "--webdav-url", Description: "URL of http host to connect to"},
	{Text: "--webdav-user", Description: "User name"},
	{Text: "--webdav-vendor", Description: "Name of the Webdav site/service/software you are using"},
	{Text: "--yandex-client-id", Description: "Yandex Client Id"},
	{Text: "--yandex-client-secret", Description: "Yandex Client Secret"},
	{Text: "--yandex-encoding", Description: "This sets the encoding for the backend."},
	{Text: "--yandex-unlink", Description: "Remove existing public link to file/folder with link command rather than creating."},
}
